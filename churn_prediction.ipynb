{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_MyftBmpKMw"
   },
   "source": [
    "# 環境整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63892,
     "status": "ok",
     "timestamp": 1750296590811,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "_UcFUxjblxm3",
    "outputId": "aaf9ca7f-b8c8-4b6c-c5f2-5d5ee4562a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting japanize-matplotlib\n",
      "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from japanize-matplotlib) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.17.0)\n",
      "Building wheels for collected packages: japanize-matplotlib\n",
      "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120257 sha256=b29011fddc1a2a86a4e41fd8438f29b3445d4e478bd2764ebe5f3d7e07696388\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/a1/71/b8faeb93276fed10edffcca20746f1ef6f8d9e071eee8425fc\n",
      "Successfully built japanize-matplotlib\n",
      "Installing collected packages: japanize-matplotlib\n",
      "Successfully installed japanize-matplotlib-1.1.3\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, alembic, optuna\n",
      "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n",
      "Collecting optuna-integration[lightgbm]\n",
      "  Downloading optuna_integration-4.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.4.0)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.5.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (1.15.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (1.16.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (2.0.41)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (3.6.0)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (4.14.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[lightgbm]) (3.2.3)\n",
      "Downloading optuna_integration-4.4.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: optuna-integration\n",
      "Successfully installed optuna-integration-4.4.0\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
      "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: catboost\n",
      "Successfully installed catboost-1.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install japanize-matplotlib\n",
    "!pip install optuna\n",
    "!pip install optuna-integration[lightgbm]\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 18328,
     "status": "ok",
     "timestamp": 1750296609151,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "AEycCTrgmuOb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, roc_curve, auc, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import differential_evolution\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "from optuna.integration import lightgbm as lgb_optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1750299479245,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "ZRL45_WxmwF8",
    "outputId": "958d624a-7aea-49e9-e7c6-2c69407eae85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1750300356445,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "SCvupanimxiu"
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('drive/MyDrive/UTTC/train_data.csv')\n",
    "test = pd.read_csv('drive/MyDrive/UTTC/test_data.csv')\n",
    "submission = pd.read_csv('drive/MyDrive/UTTC/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPKjJyOXpNXL"
   },
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1750300357461,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "BB52IF_Y-CZF"
   },
   "outputs": [],
   "source": [
    "train['Churn'].replace({'No': 0, 'Yes': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1750300357527,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "ZZJJ0UvnwnjP"
   },
   "outputs": [],
   "source": [
    "train['SeniorCitizen'].replace({'No': 0, 'Yes': 1}, inplace=True)\n",
    "test['SeniorCitizen'].replace({'No': 0, 'Yes': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750300357529,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "Yblce04Hm3my"
   },
   "outputs": [],
   "source": [
    "# trainデータフレームにフラグを追加\n",
    "train['No_Internet_Flag'] = train['InternetService'] == 'No'\n",
    "train['OnlineSecurity_TechSupport_Flag'] = (train['OnlineSecurity'] == 'Yes') & (train['TechSupport'] == 'Yes')\n",
    "train['Dependents_MultipleLines_Flag'] = (train['Dependents'] == 'Yes') & (train['MultipleLines'] == 'Yes')\n",
    "train['MultipleLines_OnlineSecurity_Flag'] = (train['MultipleLines'] == 'Yes') & (train['OnlineSecurity'] == 'Yes')\n",
    "\n",
    "# testデータフレームにフラグを追加\n",
    "test['No_Internet_Flag'] = test['InternetService'] == 'No'\n",
    "test['OnlineSecurity_TechSupport_Flag'] = (test['OnlineSecurity'] == 'Yes') & (test['TechSupport'] == 'Yes')\n",
    "test['Dependents_MultipleLines_Flag'] = (test['Dependents'] == 'Yes') & (test['MultipleLines'] == 'Yes')\n",
    "test['MultipleLines_OnlineSecurity_Flag'] = (test['MultipleLines'] == 'Yes') & (test['OnlineSecurity'] == 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750300357569,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "DazJIMZhm_es"
   },
   "outputs": [],
   "source": [
    "#削除するカラム\n",
    "columns_to_drop = ['customerID']\n",
    "train = train.drop(columns=columns_to_drop)\n",
    "test = test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750300357579,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "9DRHOAxInCyn"
   },
   "outputs": [],
   "source": [
    "#新規顧客のフラグ\n",
    "train[\"is_new_customer\"] = (train[\"tenure\"] < 12).astype(int)\n",
    "test[\"is_new_customer\"] = (test[\"tenure\"] < 12).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1750300357614,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "K_9Nt14PnLW0"
   },
   "outputs": [],
   "source": [
    "#契約残り月数を追加\n",
    "train['month_remainder'] = np.select(\n",
    "    [\n",
    "        train['Contract'] == 'Month-to-month',\n",
    "        train['Contract'] == 'One year',\n",
    "        train['Contract'] == 'Two year'\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        12 - (train['tenure'] % 12),\n",
    "        24 - (train['tenure'] % 24)\n",
    "    ],\n",
    "    default=np.nan  # 念のため他の契約形式があれば\n",
    ")\n",
    "\n",
    "test['month_remainder'] = np.select(\n",
    "    [\n",
    "        test['Contract'] == 'Month-to-month',\n",
    "        test['Contract'] == 'One year',\n",
    "        test['Contract'] == 'Two year'\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        12 - (test['tenure'] % 12),\n",
    "        24 - (test['tenure'] % 24)\n",
    "    ],\n",
    "    default=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1750300358409,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "snwMO1HsnYF0"
   },
   "outputs": [],
   "source": [
    "#その他の新変数\n",
    "service_cols = ['PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "train['NumServices'] = train[service_cols].apply(lambda x: sum(x == 'Yes'), axis=1)\n",
    "test['NumServices'] = test[service_cols].apply(lambda x: sum(x == 'Yes'), axis=1)\n",
    "\n",
    "train['RiskyContract'] = ((train['Contract'] == 'Month-to-month') & (train['PaperlessBilling'] == 'Yes')).astype(int)\n",
    "test['RiskyContract'] = ((test['Contract'] == 'Month-to-month') & (test['PaperlessBilling'] == 'Yes')).astype(int)\n",
    "\n",
    "train['RiskyContract2'] = ((train['Contract'] == 'Month-to-month') & (train['PhoneService'] == 'No')).astype(int)\n",
    "test['RiskyContract2'] = ((test['Contract'] == 'Month-to-month') & (test['PhoneService'] == 'No')).astype(int)\n",
    "\n",
    "train[\"SeniorPaperless\"] = (train[\"SeniorCitizen\"] == 1) & (train[\"PaperlessBilling\"] == \"Yes\")\n",
    "test[\"SeniorPaperless\"] = (test[\"SeniorCitizen\"] == 1) & (test[\"PaperlessBilling\"] == \"Yes\")\n",
    "\n",
    "train[\"Is_Monthly_Electronic\"] = (train[\"Contract\"] == \"Month-to-month\") & (train[\"PaymentMethod\"] == \"Electronic check\")\n",
    "test[\"Is_Monthly_Electronic\"] = (test[\"Contract\"] == \"Month-to-month\") & (test[\"PaymentMethod\"] == \"Electronic check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1750300358452,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "DVpmGOjAnnCh"
   },
   "outputs": [],
   "source": [
    "# 空白文字（\" \"）や文字列が混じっていても、数値に変換できるようにする\n",
    "train['TotalCharges'] = pd.to_numeric(train['TotalCharges'], errors='coerce')\n",
    "test['TotalCharges'] = pd.to_numeric(test['TotalCharges'], errors='coerce')\n",
    "train['TotalCharges'] = train['TotalCharges'].fillna(0)\n",
    "test['TotalCharges'] = test['TotalCharges'].fillna(0)\n",
    "\n",
    "train['ExpectedGap'] = train['MonthlyCharges'] * train['tenure'] - train['TotalCharges']\n",
    "test['ExpectedGap'] = test['MonthlyCharges'] * test['tenure'] - test['TotalCharges']\n",
    "\n",
    "train[\"MonthlyCharges\"] = np.log1p(train[\"MonthlyCharges\"])\n",
    "test[\"MonthlyCharges\"] = np.log1p(test[\"MonthlyCharges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1750300358482,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "oxkKK7TxngM6"
   },
   "outputs": [],
   "source": [
    "#予め、重回帰分析を行ったところ、各サービスの単価が判明。単価でカテゴリデータをエンコーディング。\n",
    "def encode_services(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['InternetService'] = df['InternetService'].map({\n",
    "        'Fiber optic': 50,\n",
    "        'DSL': 25\n",
    "    }).fillna(0)\n",
    "\n",
    "    df['PhoneService'] = df['PhoneService'].map({'Yes': 20}).fillna(0)\n",
    "    df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 10}).fillna(0)\n",
    "    df['StreamingTV'] = df['StreamingTV'].map({'Yes': 10}).fillna(0)\n",
    "    df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 5}).fillna(0)\n",
    "    df['TechSupport'] = df['TechSupport'].map({'Yes': 5}).fillna(0)\n",
    "    df['MultipleLines'] = df['MultipleLines'].map({'Yes': 5}).fillna(0)\n",
    "    df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 5}).fillna(0)\n",
    "    df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 5}).fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "# エンコーディング適用\n",
    "train = encode_services(train)\n",
    "test = encode_services(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1750300358523,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "DhlOu2pooXex"
   },
   "outputs": [],
   "source": [
    "binary_cols = ['Partner', 'Dependents', 'PaperlessBilling']\n",
    "\n",
    "# 変換マップ\n",
    "yes_no_map = {'Yes': 1, 'No': 0}\n",
    "\n",
    "# train, test 両方に変換を適用\n",
    "for col in binary_cols:\n",
    "    if col in train.columns:\n",
    "        train[col] = train[col].map(yes_no_map)\n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].map(yes_no_map)\n",
    "\n",
    "train['gender'].replace({'Male': 0, 'Female': 1}, inplace=True)\n",
    "test['gender'].replace({'Male': 0, 'Female': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750300358553,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "HVXu2kHPocyT"
   },
   "outputs": [],
   "source": [
    "onehot_cols = [\n",
    "    'PaymentMethod', 'Contract'\n",
    "]\n",
    "\n",
    "# train, test 両方に同じカテゴリを持たせるため、まず結合\n",
    "train['__is_train__'] = 1\n",
    "test['__is_train__'] = 0\n",
    "combined = pd.concat([train, test], axis=0)\n",
    "\n",
    "# One-Hot Encoding（NaNは無視されます）\n",
    "combined = pd.get_dummies(combined, columns=onehot_cols, drop_first=False)\n",
    "\n",
    "# 再び train/test に分割\n",
    "train = combined[combined['__is_train__'] == 1].drop(columns='__is_train__').reset_index(drop=True)\n",
    "test = combined[combined['__is_train__'] == 0].drop(columns='__is_train__').reset_index(drop=True)\n",
    "test = test.drop(\"Churn\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1750300358691,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "hq5J0GlYojrM"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(\"Churn\", axis=1).copy()\n",
    "X_test = test\n",
    "X_all = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "X_train_scaled = X_all_scaled[:len(train)]\n",
    "X_test_scaled = X_all_scaled[len(train):]\n",
    "\n",
    "#共分散行列の逆行列を作成（trainデータに基づく）\n",
    "mean_vec = np.mean(X_train_scaled, axis=0)\n",
    "cov_matrix = np.cov(X_train_scaled, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.pinv(cov_matrix)\n",
    "\n",
    "#マハラノビス距離を計算することで、異常値を可視化\n",
    "mahal_train = [distance.mahalanobis(row, mean_vec, inv_cov_matrix) for row in X_train_scaled]\n",
    "mahal_test = [distance.mahalanobis(row, mean_vec, inv_cov_matrix) for row in X_test_scaled]\n",
    "\n",
    "#結果を元データに追加\n",
    "train[\"Mahalanobis\"] = mahal_train\n",
    "test[\"Mahalanobis\"] = mahal_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2QaVCZxpIwj"
   },
   "source": [
    "# 機械学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25718,
     "status": "ok",
     "timestamp": 1750300390216,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "J1Yn3d04pXHt"
   },
   "outputs": [],
   "source": [
    "# 特徴量と目的変数の分離\n",
    "y_train = train[\"Churn\"].values\n",
    "X_train = train.drop(\"Churn\", axis=1).values\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# ====== train にスタッキング用のモデル出力列を追加 ======\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_meta_features = {\n",
    "    \"model_mlp\": np.zeros(len(train)),\n",
    "    \"model_gb\": np.zeros(len(train))\n",
    "}\n",
    "\n",
    "for train_idx, valid_idx in kf.split(X_train_std):\n",
    "    X_tr, X_val = X_train_std[train_idx], X_train_std[valid_idx]\n",
    "    y_tr = y_train[train_idx]\n",
    "    model_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),  # 隠れ層の構成\n",
    "        max_iter=500,\n",
    "        alpha=0.001,                  # 正則化\n",
    "        random_state=0,\n",
    "        early_stopping=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    model_gb = GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    model_mlp.fit(X_tr, y_tr)\n",
    "    model_gb.fit(X_tr, y_tr)\n",
    "\n",
    "    train_meta_features[\"model_mlp\"][valid_idx] = model_mlp.predict_proba(X_val)[:, 1]\n",
    "    train_meta_features[\"model_gb\"][valid_idx] = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# カラムとして追加\n",
    "for name in train_meta_features:\n",
    "    train[name] = train_meta_features[name]\n",
    "\n",
    "# ====== test にも各モデルの確率出力を追加 ======\n",
    "X_test_std = sc.transform(test.values)\n",
    "\n",
    "test[\"model_mlp\"] = model_mlp.predict_proba(X_test_std)[:, 1]\n",
    "test[\"model_gb\"] = model_gb.predict_proba(X_test_std)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4498,
     "status": "ok",
     "timestamp": 1750300394736,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "fDd40DUHp1Ux",
    "outputId": "27a9b2f1-d83d-48a6-9210-32f086d1f5fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1343, number of negative: 3727\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5070, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 1364, number of negative: 3706\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5070, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 1351, number of negative: 3719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5070, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 1348, number of negative: 3722\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5070, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 1349, number of negative: 3722\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5071, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 1339, number of negative: 3732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5071, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 1333, number of negative: 3738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5071, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 1349, number of negative: 3722\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5071, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 1345, number of negative: 3726\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5071, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 1343, number of negative: 3728\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1730\n",
      "[LightGBM] [Info] Number of data points in the train set: 5071, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Best Threshold: 0.43999999999999984\n",
      "Optimized Train F1 Score: 0.61643\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "X = train.drop(\"Churn\", axis=1).values\n",
    "y = train[\"Churn\"].values\n",
    "\n",
    "# 標準化\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "# クロスバリデーション設定\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=0)\n",
    "\n",
    "# メタ特徴量と特徴量重要度を初期化\n",
    "train_valid_lgb = np.zeros(y.shape)\n",
    "feature_importances = np.zeros(X_std.shape[1])\n",
    "\n",
    "# 各foldでモデル学習\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_std)):\n",
    "    X_train, X_valid = X_std[train_index], X_std[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    # モデル定義（不均衡対策 + ハイパーパラメータ調整）\n",
    "    model_lgb = LGBMClassifier(\n",
    "        random_state=0,\n",
    "        class_weight='balanced',\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1\n",
    "    )\n",
    "    model_lgb.fit(X_train, y_train)\n",
    "\n",
    "    # 検証用の確率予測\n",
    "    y_prob = model_lgb.predict_proba(X_valid)[:, 1]\n",
    "    train_valid_lgb[valid_index] = y_prob\n",
    "\n",
    "    # 特徴量重要度を加算\n",
    "    feature_importances += model_lgb.feature_importances_\n",
    "\n",
    "# ======== しきい値最適化 =============\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (train_valid_lgb > t).astype(int)\n",
    "    score = f1_score(y, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_thresh = t\n",
    "\n",
    "# 最終予測とF1スコア\n",
    "final_preds = (train_valid_lgb > best_thresh).astype(int)\n",
    "print(f\"Best Threshold: {best_thresh}\")\n",
    "print(f\"Optimized Train F1 Score: {round(best_f1, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1750300395572,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "Ypgxfp9Dp2MM",
    "outputId": "2b110eec-6477-4c8f-be8f-3b3e3bfa3720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.5599999999999997\n",
      "Optimized Train F1 Score: 0.6297\n"
     ]
    }
   ],
   "source": [
    "# 標準化（Logistic Regressionでは必須）\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "# クロスバリデーション設定\n",
    "kf = KFold(n_splits=19, shuffle=True, random_state=0)\n",
    "\n",
    "# メタ特徴量\n",
    "train_valid_lr = np.zeros(y.shape)\n",
    "\n",
    "# 各foldでモデル学習\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_std)):\n",
    "    X_train, X_valid = X_std[train_index], X_std[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    model_lr = LogisticRegression(\n",
    "        penalty='l2',              # L2正則化（標準的）\n",
    "        solver='liblinear',       # 小規模データに強い\n",
    "        class_weight='balanced',  # 不均衡対策\n",
    "        random_state=0\n",
    "    )\n",
    "    model_lr.fit(X_train, y_train)\n",
    "\n",
    "    # 確率予測\n",
    "    y_prob = model_lr.predict_proba(X_valid)[:, 1]\n",
    "    train_valid_lr[valid_index] = y_prob\n",
    "\n",
    "# ======== しきい値最適化 =============\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (train_valid_lr > t).astype(int)\n",
    "    score = f1_score(y, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_thresh = t\n",
    "\n",
    "# 最終予測とF1スコア\n",
    "final_preds = (train_valid_lr > best_thresh).astype(int)\n",
    "print(f\"Best Threshold: {best_thresh}\")\n",
    "print(f\"Optimized Train F1 Score: {round(best_f1, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15720,
     "status": "ok",
     "timestamp": 1750300411298,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "KixaXfYOp7z8",
    "outputId": "61b3c242-94c6-4dbd-c07f-a1d224171efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.4099999999999998\n",
      "Optimized Train F1 Score: 0.62609\n"
     ]
    }
   ],
   "source": [
    "# 標準化（Random Forestは非線形モデルなので不要だが、LightGBMと比較のためにそのまま）\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "# クロスバリデーション設定\n",
    "kf = KFold(n_splits=16, shuffle=True, random_state=0)\n",
    "\n",
    "# メタ特徴量と特徴量重要度を初期化\n",
    "train_valid_rf = np.zeros(y.shape)\n",
    "feature_importances = np.zeros(X_std.shape[1])\n",
    "\n",
    "# 各foldでモデル学習\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_std)):\n",
    "    X_train, X_valid = X_std[train_index], X_std[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    model_rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced',  # 不均衡データ対策\n",
    "        random_state=0,\n",
    "        n_jobs=-1  # 並列処理\n",
    "    )\n",
    "    model_rf.fit(X_train, y_train)\n",
    "\n",
    "    # 検証用の確率予測\n",
    "    y_prob = model_rf.predict_proba(X_valid)[:, 1]\n",
    "    train_valid_rf[valid_index] = y_prob\n",
    "\n",
    "    # 特徴量重要度を加算\n",
    "    feature_importances += model_rf.feature_importances_\n",
    "\n",
    "# ======== しきい値最適化 =============\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (train_valid_rf > t).astype(int)\n",
    "    score = f1_score(y, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_thresh = t\n",
    "\n",
    "# 最終予測とF1スコア\n",
    "final_preds = (train_valid_rf > best_thresh).astype(int)\n",
    "print(f\"Best Threshold: {best_thresh}\")\n",
    "print(f\"Optimized Train F1 Score: {round(best_f1, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12404,
     "status": "ok",
     "timestamp": 1750300423709,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "s0qLGrmbqAGD",
    "outputId": "6e6ae1f2-2466-443a-f114-8ac37a6a719c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.5399999999999998\n",
      "Optimized Train F1 Score: 0.62431\n"
     ]
    }
   ],
   "source": [
    "# 標準化（CatBoostは本来不要ですが、LightGBMと比較用に残しています）\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "# クロスバリデーション設定\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# メタ特徴量と特徴量重要度を初期化\n",
    "train_valid_cb = np.zeros(y.shape)\n",
    "feature_importances = np.zeros(X_std.shape[1])\n",
    "\n",
    "# class weight 計算（不均衡データ対策）\n",
    "class_weights = [1, (len(y) - sum(y)) / sum(y)]\n",
    "\n",
    "# 各foldでモデル学習\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_std)):\n",
    "    X_train, X_valid = X_std[train_index], X_std[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    model_cb = CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        random_seed=0,\n",
    "        verbose=0,\n",
    "        class_weights=class_weights\n",
    "    )\n",
    "    model_cb.fit(X_train, y_train)\n",
    "\n",
    "    # 検証用の確率予測\n",
    "    y_prob = model_cb.predict_proba(X_valid)[:, 1]\n",
    "    train_valid_cb[valid_index] = y_prob\n",
    "\n",
    "    # 特徴量重要度を加算\n",
    "    feature_importances += model_cb.get_feature_importance()\n",
    "\n",
    "# ======== しきい値最適化 =============\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (train_valid_cb > t).astype(int)\n",
    "    score = f1_score(y, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_thresh = t\n",
    "\n",
    "# 最終予測とF1スコア\n",
    "final_preds = (train_valid_cb > best_thresh).astype(int)\n",
    "print(f\"Best Threshold: {best_thresh}\")\n",
    "print(f\"Optimized Train F1 Score: {round(best_f1, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1750300424869,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "rz4W4K6cqFEv",
    "outputId": "0a303c76-b8f2-4ff3-d9ec-231e44a41d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights: [0.07652765 0.69651854 0.12376249 0.10319131]\n",
      "Best threshold: 0.5313\n",
      "Train F1 Score: 0.63226\n"
     ]
    }
   ],
   "source": [
    "train_valids = [train_valid_lgb, train_valid_lr, train_valid_rf,\n",
    "                train_valid_cb]\n",
    "\n",
    "# ======== 最適化関数定義：重み + 閾値 (0.1～0.9) を同時最適化 ========\n",
    "def global_objective(params):\n",
    "    weights = np.array(params[:-1])\n",
    "    weights = weights / weights.sum()  # 正規化\n",
    "    threshold = params[-1]\n",
    "\n",
    "    # 加重平均\n",
    "    blended = np.average(train_valids, axis=0, weights=weights)\n",
    "    preds = (blended >= threshold).astype(int)\n",
    "    score = f1_score(y, preds)\n",
    "    return -score  # minimize用に負\n",
    "\n",
    "# ======== 最適化設定（重み7つ + 閾値1つ = 8次元）========\n",
    "bounds = [(0, 1)] * 4 + [(0.1, 0.9)]  # 閾値は0.1～0.9と制限\n",
    "\n",
    "result = differential_evolution(global_objective, bounds, seed=42)\n",
    "best_params = result.x\n",
    "best_weights = best_params[:-1]\n",
    "best_weights /= best_weights.sum()  # 正規化\n",
    "best_thresh = best_params[-1]\n",
    "\n",
    "print(\"Best weights:\", best_weights)\n",
    "print(\"Best threshold:\", round(best_thresh, 4))\n",
    "print(\"Train F1 Score:\", round(-result.fun, 5))\n",
    "\n",
    "# ========== FinalModel クラス定義 ==========\n",
    "class FinalModel:\n",
    "    def __init__(self, models, weights, scaler, threshold):\n",
    "        self.models = models\n",
    "        self.weights = weights / np.sum(weights)\n",
    "        self.scaler = scaler\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_std = self.scaler.transform(X)\n",
    "        preds = [model.predict_proba(X_std)[:, 1] for model in self.models]\n",
    "        return np.average(preds, axis=0, weights=self.weights)\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= self.threshold).astype(int)\n",
    "\n",
    "# ========== モデル構築 ==========\n",
    "models = [model_lgb, model_lr, model_rf, model_cb] # すでに学習済み\n",
    "final_model = FinalModel(models=models, weights=best_weights, scaler=sc, threshold=best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQOVHDqvpS0a"
   },
   "source": [
    "# 予測結果の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1750300464621,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "ptagifprpXhs",
    "outputId": "74afc992-6aa8-4ddc-d7de-660fec14a782"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_label = final_model.predict(test)\n",
    "y_pred_label = np.where(y_pred_label == 1, \"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750300472844,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "xhyCkFVVxTno"
   },
   "outputs": [],
   "source": [
    "submission['Churn'] = y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1750300474662,
     "user": {
      "displayName": "Takuto O.",
      "userId": "13111756173360567963"
     },
     "user_tz": -540
    },
    "id": "QWxbz_BbxgbM",
    "outputId": "74c78760-eab4-44f6-a1df-9c1fe9a18e57"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_99341835-a3a8-4ff9-95bd-afab17cbf51c\", \"submission_prediction.csv\", 20253)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "submission.to_csv('submission_prediction.csv', index=False)\n",
    "files.download('submission_prediction.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhsLD3Puw9FpC0anfX9GeF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
